{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cacd67e3-2967-4086-ac50-63b3f9d7c6f3",
   "metadata": {},
   "source": [
    "## Ground-Up CENSUS FOOD DESERT ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290c140c-3b39-4799-a73a-0039ac22c7ae",
   "metadata": {},
   "source": [
    "#### This module is to ignore potential unwanted warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c03afe9-1e86-4335-af78-210aafbb35a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7379f603-0f66-48f2-85a2-d3ee203db3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # manipulation of datasets  \n",
    "import geopandas as gpd # manipulation of datasets with shapes/geometry\n",
    "import matplotlib.pyplot as plt # visualization of the datasets\n",
    "import os\n",
    "import numpy as np\n",
    "import requests \n",
    "import folium\n",
    "from shapely.geometry import Point, box\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee34599-9f1d-4de3-8367-6cef27482fa3",
   "metadata": {},
   "source": [
    "#### Importing Network Analysis Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cdb83d-ff21-4865-9892-5ca7bfabb66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import osmnx as ox\n",
    "import networkx as nx\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa4de1b-43f7-493a-a141-3070c69bcf42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "590d9b4b-0845-4e74-91ea-c99db3540d6e",
   "metadata": {},
   "source": [
    "### Reading State Census Tract File for a Year. (Choose Desired Year)\n",
    "\n",
    "#### This file can be found at https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-line-file.2019.html#list-tab-790442341"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c622c1-bb58-40de-a5fe-978d52c339a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "State = gpd.read_file(\"???.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61eaaf56-5d9e-4254-b9b0-84eb747b2a4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "State # see the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f767d2cd-0a8d-4434-b5fc-4bf1d54726bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ebf2a2b9-f14a-4321-88d9-58bb94a3f9ac",
   "metadata": {},
   "source": [
    "### Download Poverty, Income, Population, Vehicle Access Datasets from data.census.gov\n",
    "\n",
    "#### To compare with USDA use advanced filter from 2014-2018 since they have food desert data until 2019.\n",
    "#### For latest data i.e., in 2025, use ACS 2019-2024 Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b2a6a1-8b86-4f08-8032-6cdc9eb09fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# poverty 2014-2018 ACS \n",
    "poverty = pd.read_csv(\"????.csv\",skiprows=[1,1]) # we skip the 2nd row (since python indexing works as 0 , 1, 2 ....) as it a filler row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b17718b-4292-468f-92d0-62773a50e8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# income 2014-2018 ACS\n",
    "income = pd.read_csv(\"????.csv\",skiprows=[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b865fc-2e24-4fe4-809a-20747773272c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# population 2019, derived from 2010 census\n",
    "population = pd.read_csv(\"????.csv\",skiprows=[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a27d9f8-6524-411b-a8a6-8d835262c368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vehicle access 2014-2018 ACS\n",
    "vehicle = pd.read_csv(\"????.csv\",skiprows=[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557d9daf-7a10-48b6-9e63-952f817339eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cf09b6-e16b-4efb-ac40-5d235af253d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "poverty['GEO_ID'] = poverty['GEO_ID'].str.split('S').str[1] # we do not change anything here since we fix the GEOID to enable joing with State Shape file\n",
    "income['GEO_ID'] = income['GEO_ID'].str.split('S').str[1]\n",
    "population['GEO_ID'] = population['GEO_ID'].str.split('S').str[1]\n",
    "vehicle['GEO_ID'] = vehicle['GEO_ID'].str.split('S').str[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728ada3c-4dcf-4904-b54e-ee4865335a81",
   "metadata": {},
   "source": [
    "### Merge the Datasets with Census Tract for the State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766d7cba-ff42-4e00-bd74-f31ad43ea19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert both columns of shape and census data to same data type (string in this case) to ensure proper merging\n",
    "State[\"GEOID\"] = State[\"GEOID\"].astype(str)\n",
    "poverty[\"GEO_ID\"] = poverty[\"GEO_ID\"].astype(str)\n",
    "income[\"GEO_ID\"] = income[\"GEO_ID\"].astype(str)\n",
    "population[\"GEO_ID\"] = population[\"GEO_ID\"].astype(str)\n",
    "vehicle[\"GEO_ID\"] = vehicle[\"GEO_ID\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bbcbc6-f4a6-43f2-bed5-e712259e675b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select specific columns from each DataFrame\n",
    "# Adding GEO_ID for merging\n",
    "# Rename columns from each DataFrame\n",
    "# all of this should remain constant and should not change as data.census.gov follow a standard for assigning particular to variables. \n",
    "\n",
    "poverty_subset = poverty.iloc[:, [0, 2, 124, 126]].rename(columns={\n",
    "    poverty.columns[2]: 'totalpop',\n",
    "    poverty.columns[124]: 'belowpoverty',\n",
    "    poverty.columns[126]: 'percentpoverty',\n",
    "    poverty.columns[0]: 'GEO_ID'\n",
    "})\n",
    "\n",
    "income_subset = income.iloc[:, [0, 2, 24, 26, 34, 100, 106]].rename(columns={\n",
    "    income.columns[2]: 'tothouseholds',\n",
    "    income.columns[24]: 'medhouse',\n",
    "    income.columns[26]: 'meanhouse',\n",
    "    income.columns[34]: 'totfam',\n",
    "    income.columns[100]: 'medfam',\n",
    "    income.columns[106]: 'meanfam',\n",
    "    income.columns[0]: 'GEO_ID'\n",
    "})\n",
    "\n",
    "population_subset = population.iloc[:, [0, 2, 172]].rename(columns={\n",
    "    population.columns[2]: 'pop2010',\n",
    "    population.columns[172]: 'houseunits',\n",
    "    population.columns[0]: 'GEO_ID'\n",
    "})\n",
    "\n",
    "vehicle_subset = vehicle.iloc[:, [0, 2, 54, 78]].rename(columns={\n",
    "    vehicle.columns[2]: 'occhousingunits',\n",
    "    vehicle.columns[54]: 'novehicles',\n",
    "    vehicle.columns[78]: 'percenthouseunits',\n",
    "    vehicle.columns[0]: 'GEO_ID'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e392694f-4b4a-4da7-930c-2702644aaf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all DataFrames to enable visualization\n",
    "State_Food = (State\n",
    "                     .merge(poverty_subset, left_on=\"GEOID\", right_on=\"GEO_ID\", how=\"inner\")\n",
    "                     .drop(columns=\"GEO_ID\")  # Drop GEO_ID after every merge\n",
    "                     .merge(income_subset, left_on=\"GEOID\", right_on=\"GEO_ID\", how=\"inner\")\n",
    "                     .drop(columns=\"GEO_ID\")  \n",
    "                     .merge(population_subset, left_on=\"GEOID\", right_on=\"GEO_ID\", how=\"inner\")\n",
    "                     .drop(columns=\"GEO_ID\") \n",
    "                     .merge(vehicle_subset, left_on=\"GEOID\", right_on=\"GEO_ID\", how=\"inner\")\n",
    "                     .drop(columns=\"GEO_ID\"))  \n",
    "\n",
    "# If there are still duplicates, remove them\n",
    "State_Food = State_Food.loc[:, ~State_Food.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcdcad8-5737-4514-bf47-f02ee686c39e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "State_Food # display the final file that we will be working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c9dd04-2c5b-45c6-97f2-90b2ce1abeba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4428b02-2eb5-4de3-a219-ced39a1c9f2e",
   "metadata": {},
   "source": [
    "### Fix/Clean the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2146563-9cb2-4822-9717-5dea58994da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace X with NaN if needed\n",
    "State_Food = State_Food.replace('(X)', np.nan) # usually USDA uses (X) instead of NaN to represent no value so this should be changed \n",
    "                                                # to enable plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a47732-d312-4d48-8f8b-80836e97e985",
   "metadata": {},
   "source": [
    "### Save the Final State Food Desert File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5363b08c-7e56-4cd4-8080-b9ab057c8201",
   "metadata": {},
   "outputs": [],
   "source": [
    "State_Food.to_file(\"?????.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07f9d02-2737-4051-812e-3e0be2d945d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dcf47759-fd98-49c1-9803-a5bcfec10132",
   "metadata": {},
   "source": [
    "### Dividing by Grid Cells (0.5 km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77bad0d-f655-49ce-80e3-21882f740765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Define US bounds in lat/lon (WGS84, EPSG:4326)\n",
    "us_bounds = {\n",
    "    'minx': -125.0,  # Western edge (Washington)\n",
    "    'miny': 24.396308,  # Southern edge (Florida)\n",
    "    'maxx': -66.93457,  # Eastern edge (Maine)\n",
    "    'maxy': 49.384358  # Northern edge (Washington/Minnesota)\n",
    "}\n",
    "\n",
    "# Create a bounding box for the US in lat/lon\n",
    "us_bbox = gpd.GeoDataFrame(\n",
    "    geometry=[box(us_bounds['minx'], us_bounds['miny'], us_bounds['maxx'], us_bounds['maxy'])],\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "\n",
    "# Project to Albers Equal Area (EPSG:5070) for accurate grid cell size\n",
    "us_bbox = us_bbox.to_crs(epsg=5070)\n",
    "minx, miny, maxx, maxy = us_bbox.total_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e34b784-d635-4ae5-a27e-9e874f9dc6a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3f4a99-7068-49fd-86e7-d4945ba68c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define grid cell size (0.5 km = 500 meters)\n",
    "cell_size = 500\n",
    "\n",
    "# Create a grid covering the US\n",
    "x_coords = np.arange(minx, maxx + cell_size, cell_size)\n",
    "y_coords = np.arange(miny, maxy + cell_size, cell_size)\n",
    "grid_cells = [box(x, y, x + cell_size, y + cell_size) for x in x_coords[:-1] for y in y_coords[:-1]]\n",
    "grid = gpd.GeoDataFrame({'geometry': grid_cells}, crs=us_bbox.crs)\n",
    "\n",
    "# Step 2: Load state census tracts and project to the same CRS\n",
    "state_tracts = State_Food.copy()\n",
    "state_tracts = state_tracts.to_crs(epsg=5070) # Albers Equal Area, this can be changed later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816d4d61-14d3-42cc-b2ac-586ab5915412",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf99366-dfba-46d4-86c4-7bb87c63acdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clip the US grid to States boundaries, such that we are left with grids only in the State\n",
    "state_bounds = state_tracts.dissolve().geometry[0]  # Combine all State tracts into one geometry\n",
    "grid_state = gpd.sjoin(grid, state_tracts[['geometry']], how='inner', predicate='intersects')\n",
    "grid_state = grid_indiana.drop(columns=['index_right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e7e9cb-7e01-4306-8728-321343b457d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84869d4-02d0-4b35-b7a4-12bb92341f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Intersect grid with State tracts and calculate intersection areas, not every grid will hold the same weightage (the ones on the edge for ex)\n",
    "grid_state = gpd.overlay(grid_state, state_tracts, how='intersection')\n",
    "grid_state['area'] = grid_state.geometry.area  # Area of each intersection in square meters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715f964b-4551-484a-91b2-a0c540cef1f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fabef1e-4783-4c00-abb4-a437b6c5a914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Assign population based on tract population (using 'pop2010')\n",
    "# Calculate tract area and population density based on grids size\n",
    "state_tracts['tract_area'] = state_tracts.geometry.area\n",
    "state_tracts['pop_density'] = state_tracts['pop2010'].astype(float) / state_tracts['tract_area']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db5ef13-60a0-41b5-b30c-601a8ed1eb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge population density into grid_indiana\n",
    "grid_state = grid_indiana.merge(state_tracts[['GEOID', 'pop_density']], on='GEOID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579e8c5a-6dd2-4608-939a-2fa813152f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate population for each grid cell portion\n",
    "grid_state['grid_population'] = grid_state['area'] * grid_state['pop_density']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413bd269-6360-486e-ac40-0e3c85a80c06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5921aad2-4521-4e5b-a2a8-d3c2da030063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Step: Handle grid cells spanning multiple tracts by summing population contributions\n",
    "grid_state['grid_id'] = grid_state.index  # Temporary unique ID\n",
    "grid_population = grid_state.groupby('grid_id')['grid_population'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5e740b-6e0e-41df-b162-39f437d49bbf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid_state # this is what we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b132fbfa-b2d1-4adb-b39e-7ae3d148daa3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1921271-4dc0-479d-a568-c90db15add70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the grided file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5798d0e1-e1ab-407e-94e0-6c89ec069cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_state.to_file(\"?????.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b96d80-1c14-493b-b58a-3011d5752286",
   "metadata": {},
   "source": [
    "## Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e2276d-4175-4adc-8053-85223e319b89",
   "metadata": {},
   "source": [
    "### Read the Grided State File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4467f953-a826-4e79-9288-6195fae69dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_state = gpd.read_file(\"?????.shp\") # read the shape file if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758b2b4b-dd22-44ea-bfb1-9f56c31ef819",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_state.plot() # see how the map looks like, should take ~1 min to load since there a lot of grids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1738f5-9522-4fbb-a766-ec4e9e42f3b7",
   "metadata": {},
   "source": [
    "### Centroid Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb958de-5f8e-49a5-871a-71ad0e309da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Calculate centroids for each grid cell in grid_indiana\n",
    "grid_state['centroid'] = grid_state.geometry.centroid # this is for our Network Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6653ce6c-8792-4dec-a354-4dc20f3d7e6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd5c5332-b278-45c8-9b28-5d40d4a86cb0",
   "metadata": {},
   "source": [
    "## Get Grocery Locations through Open Street Map Geocoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbb4138-072b-4cec-ac90-56c08a58f1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking up when the store opens opened to filter by year??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8548fa0a-fbbd-4448-9288-3fb5dd7893fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_locations(categories, queries, cities, state, country, brand=None):\n",
    "    \"\"\"Fetch locations from OpenStreetMap using Overpass API.\"\"\"\n",
    "    overpass_url = \"http://overpass-api.de/api/interpreter\"\n",
    "    all_locations = []\n",
    "\n",
    "    # Construct the optional brand filter\n",
    "    brand_filter = f'[\"brand\"=\"{brand}\"]' if brand else ''\n",
    "\n",
    "    # Handle multiple categories, queries, and cities\n",
    "    if not categories or not queries or not cities:\n",
    "        print(\"No categories, queries, or cities provided.\")\n",
    "        return []\n",
    "\n",
    "    for category in categories:\n",
    "        for city in cities:\n",
    "            for query in queries:\n",
    "                overpass_query = f\"\"\"\n",
    "                [out:json];\n",
    "                area[name=\"{city}\"]->.searchArea;\n",
    "                (\n",
    "                  node[\"{category}\"=\"{query}\"]{brand_filter}(area.searchArea);\n",
    "                  way[\"{category}\"=\"{query}\"]{brand_filter}(area.searchArea);\n",
    "                  relation[\"{category}\"=\"{query}\"]{brand_filter}(area.searchArea);\n",
    "                );\n",
    "                out center;\n",
    "                \"\"\"\n",
    "                \n",
    "                try:\n",
    "                    response = requests.get(overpass_url, params={'data': overpass_query})\n",
    "                    response.raise_for_status()\n",
    "                    data = response.json()\n",
    "                    all_locations.extend(data.get(\"elements\", []))\n",
    "                except requests.exceptions.RequestException as e:\n",
    "                    print(f\"Request error for {category}={query} in {city}: {e}\")\n",
    "                except requests.exceptions.JSONDecodeError:\n",
    "                    print(f\"Error decoding JSON response from API for {category}={query} in {city}.\")\n",
    "\n",
    "    return all_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd95335b-9154-4992-9ae1-3c6abe3bf6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_locations(data, city, state, country):\n",
    "    \"\"\"Plot locations on a Folium map.\"\"\"\n",
    "    if not data:\n",
    "        print(\"No locations found.\")\n",
    "        return None\n",
    "\n",
    "    # Extract the first valid location for map centering\n",
    "    for place in data:\n",
    "        lat = place.get('lat') or (place.get('center', {}).get('lat'))\n",
    "        lon = place.get('lon') or (place.get('center', {}).get('lon'))\n",
    "        if lat and lon:\n",
    "            m = folium.Map(location=[lat, lon], zoom_start=12)\n",
    "            break\n",
    "    else:\n",
    "        print(\"No valid coordinates found.\")\n",
    "        return None\n",
    "\n",
    "    # Add markers\n",
    "    for place in data:\n",
    "        lat = place.get('lat') or (place.get('center', {}).get('lat'))\n",
    "        lon = place.get('lon') or (place.get('center', {}).get('lon'))\n",
    "        if lat and lon:\n",
    "            name = place.get('tags', {}).get('name', 'Unknown')\n",
    "            folium.Marker([lat, lon], popup=f\"{name} ({lat}, {lon})\").add_to(m)\n",
    "\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c30f7e-a139-4638-870d-1f344fa8f624",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_locations(data):\n",
    "    \"\"\"Display location names with coordinates in a DataFrame.\"\"\"\n",
    "    locations = []\n",
    "    for place in data:\n",
    "        lat = place.get('lat') or (place.get('center', {}).get('lat'))\n",
    "        lon = place.get('lon') or (place.get('center', {}).get('lon'))\n",
    "        if lat and lon:\n",
    "            name = place.get('tags', {}).get('name', 'Unknown')\n",
    "            locations.append([name, lat, lon])\n",
    "    \n",
    "    df = pd.DataFrame(locations, columns=['Name', 'Latitude', 'Longitude'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e62bb42-e71b-4757-a288-e0892e9a06ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Example Query Parameters\n",
    "category = [\"shop\"]  # General category\n",
    "queries = [\"supermarket\", \"department_store\", \"greengrocer\", \"farm\", \"health_food\", \"retail\"]  # Multiple specific queries for Food Desert\n",
    "cities = [\"????\"]\n",
    "state = \"????\"\n",
    "country = \"USA\"\n",
    "brand = None  # Change to \"Walmart\" or \"Target\" if needed or None \n",
    "\n",
    "# Fetch Data\n",
    "data = get_locations(category, queries, cities, state, country, brand)\n",
    "\n",
    "# Plot Data on Map\n",
    "map_result = plot_locations(data, cities[0] if cities else None, state, country)\n",
    "\n",
    "# Display DataFrame of Locations\n",
    "df_locations = display_locations(data)\n",
    "\n",
    "# Display the map and data\n",
    "if map_result:\n",
    "    display(map_result)\n",
    "\n",
    "display(df_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ab3c2f-9a55-4724-b598-d584fbaa44e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94383e78-279b-4074-9bf5-b0f34412307a",
   "metadata": {},
   "source": [
    "#### Convert fetched locations (df_locations) to a GeoDataFrame with Point geometries to perform distance calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff985fbf-2ff6-48db-ae71-24bd54d256ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "supermarkets = gpd.GeoDataFrame(\n",
    "    df_locations,\n",
    "    geometry=[Point(lon, lat) for lon, lat in zip(df_locations['Longitude'], df_locations['Latitude'])],\n",
    "    crs=\"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c8aaf6-f2ec-4c5a-bd02-455540c93675",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "supermarkets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9e8830-8a39-4907-a73e-55d4fbf4e9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "supermarkets = supermarkets.to_crs(epsg=5070)  # Project to Albers Equal Area since that is our projection for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a43a8c-2eb2-4cc3-8d8c-4b832bf23449",
   "metadata": {},
   "outputs": [],
   "source": [
    "supermarkets_gdf = supermarkets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777d2069-d5cb-4091-b092-739d16ee3662",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2b3652b-ddfa-4509-bc5e-8c7f5b728ad3",
   "metadata": {},
   "source": [
    "### We download the Road Network using Network Analysis Module with Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289b5eb4-ed49-453e-87f3-f1f14784d3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = ox.graph_from_place(\"??????, USA\", network_type=\"drive\") # uncomment after downloading the road-network for the area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c41fbad-b674-4b2c-b0ac-d2a06c0635aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ox.save_graphml(G, filepath=\"??????.graphml\") # save it such that you do not need to download it again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18e849e-5c9a-4b43-974e-56c480cdd00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#G = ox.load_graphml(\"?????.graphml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ac6531-0eb9-4eca-a11e-0a95ba0dba67",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = ox.project_graph(G, to_crs=\"EPSG:5070\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ba71d8-fab1-405c-8f09-cbb776650d4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ox.plot_graph(G) # plot the road network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265a660d-3961-4a47-b302-3fa774c0bcea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae9b4bad-8e46-4e16-a78b-3384b55c22ca",
   "metadata": {},
   "source": [
    "#### Calculate the Nearest Supermarket from Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735ea3d3-886c-4a87-999a-d6f0c18f1a9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96432707-6efd-4004-b6cc-af681a118d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Find nearest OSM nodes for grid centroids and supermarkets using vectorized approach\n",
    "start_time = time.time()\n",
    "\n",
    "# Extract x, y coordinates as NumPy arrays\n",
    "grid_x = grid_state['centroid'].apply(lambda point: point.x).to_numpy()\n",
    "grid_y = grid_state['centroid'].apply(lambda point: point.y).to_numpy()\n",
    "market_x = supermarkets_gdf.geometry.x.to_numpy()\n",
    "market_y = supermarkets_gdf.geometry.y.to_numpy()\n",
    "\n",
    "# Use OSMnx vectorized nearest_nodes function\n",
    "grid_state['nearest_node'] = ox.distance.nearest_nodes(G, grid_x, grid_y)\n",
    "supermarkets_gdf['nearest_node'] = ox.distance.nearest_nodes(G, market_x, market_y)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Nearest Nodes Execution Time: {end_time - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e471000-6e4e-48ec-aea4-df9a2c0c3c4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6f2743-60a7-4c1a-ae22-93d24925c6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to sets to avoid duplicates\n",
    "grid_nodes = set(grid_indiana['nearest_node'].dropna())\n",
    "market_nodes = set(supermarkets_gdf['nearest_node'].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e74058-38b8-4d8b-a858-119df96e977a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024fd2e5-d94a-41fb-9ac2-c27a6a703f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Compute shortest paths from all supermarket nodes to all grid nodes in one go\n",
    "start_time = time.time()\n",
    "\n",
    "# Use multi-source Dijkstra to find the shortest path from the closest supermarket to each node\n",
    "path_lengths = nx.multi_source_dijkstra_path_length(G, sources=market_nodes, weight='length') # much faster the single source approach\n",
    "\n",
    "# Extract distances for grid nodes only, convert to km\n",
    "grid_to_market_distances = {\n",
    "    grid_node: path_lengths.get(grid_node, float('inf')) / 1000  # Convert to km\n",
    "    for grid_node in grid_nodes\n",
    "}\n",
    "\n",
    "# Map distances back to the DataFrame\n",
    "grid_state['distance'] = grid_state['nearest_node'].map(grid_to_market_distances)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Network Distance Execution Time: {end_time - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4234e67-a736-48ed-abdc-accf1252a584",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0530259a-abd7-4629-8da1-9a9b92d8b076",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_state['distance'] = grid_state['distance'] * 0.621371 # convert to miles as done by USDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffe7570-f650-4521-a060-358140be8bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_state['distance'].median() # check the mean and median if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a882a59-0680-42db-962f-e769a6fcafa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up: drop temporary columns if desired\n",
    "grid_state = grid_state.drop(columns=['centroid', 'nearest_node']) # need to drop these in order to save the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e89490-288b-49fb-a79f-9903a2c5f22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_state.to_file(\"??????.shp\") # you can save it if you like with distances calculated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89af1eba-11b8-4c95-9d6c-4f078481b7de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41efdd37-cc97-4ce7-9f56-3b9a68d0073d",
   "metadata": {},
   "source": [
    "# Plotting Time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1b3478-c21c-4c2d-9fd3-a051f2986089",
   "metadata": {},
   "outputs": [],
   "source": [
    "State = gpd.read_file(\"???????.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da908152-57a3-4974-afff-27240606d14c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "State.columns.tolist() # see column names to understand what we are working with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f550dbd2-31d9-4a02-8f75-5bca86caf2a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8f6738-3d97-4074-84da-2a6febf002d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "State['GEOID'].describe() # just making sure the \"unique\" GEOID matches the total census tracts for the state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82be48aa-6e86-46a8-8e95-ef6b63d9e1c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67ddfaaa-4654-4c79-9d8e-b3fd32154174",
   "metadata": {},
   "source": [
    "### Pick Any Census Tract within this Grided State to see how it looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49844fdb-d6df-42b8-8299-a31bf33ecb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tract = State[State['NAMELSAD'] == '??????']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7efcd7a-7109-45c8-bc7d-21683bd5ad43",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tract['tothouseho'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e56aabc-62bd-4fac-909f-73bcb7df4637",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tract['grid_households'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5333387b-a218-43ed-a598-a4644e0bfb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tract[\"area\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316c2a47-ca94-4b16-902b-7f1a3df7a37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tract[\"grid_popul\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f578b80b-5e23-4f09-b84c-dd13d6714d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tract.plot(column='distance', legend=True, cmap='viridis') # distance\n",
    "## Darker colored grids indicates there are supermarkets closer to the grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51106ac-d394-41e0-886c-f246d097b019",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31756820-214a-4edd-b391-6d80d68c6592",
   "metadata": {},
   "source": [
    "### Read the pre-calculated State Median Income csv file (see other notebook on how to perform this!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6fbd78-140f-49f6-8a4f-66785b60226f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the metro income data\n",
    "Metro = pd.read_csv(\"???????.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77938f90-9ed5-4c7a-bc10-3427c9244b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "State[\"medfam\"] = pd.to_numeric(State[\"medfam\"], errors=\"coerce\") # coverting the columns into numeric data type to ensure numpy calculations\n",
    "State[\"percentpov\"] = pd.to_numeric(State[\"percentpov\"], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7594327-391b-482b-825a-7e1899e6f73b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e354d1c9-42aa-4789-bcfc-65f9f5ac9360",
   "metadata": {},
   "source": [
    "### Plotting Low Income, Low Access, Low Income and Low Access "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c993178-02fb-4155-8b9d-77b939fd265f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b521e584-3df5-4d7a-a5fa-dbff628966d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop low_income_status if it already exists to avoid merge conflicts\n",
    "if 'low_income_status' in State.columns:\n",
    "    State = State.drop(columns=['low_income_status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf0a5ee-9e57-42f0-91b7-e659866495ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Compute low-income status at tract level\n",
    "medfam_threshold = 0.8 * State[\"medfam\"].median()\n",
    "\n",
    "def get_metro_threshold(row, metro_df):\n",
    "    if row[\"Metro\"] == \"Yes\":\n",
    "        metro_row = metro_df[metro_df[\"Name\"] == row[\"NAME_1\"]]\n",
    "        if not metro_row.empty:\n",
    "            return 0.8 * metro_row[\"Median_Income\"].iloc[0]\n",
    "    return None\n",
    "\n",
    "def is_low_income(row, metro_df):\n",
    "    metro_threshold = get_metro_threshold(row, metro_df)\n",
    "    if row[\"percentpov\"] >= 20 or row[\"medfam\"] <= medfam_threshold or (metro_threshold is not None and row[\"medfam\"] <= metro_threshold):\n",
    "        return \"Yes\"\n",
    "    return \"No\"\n",
    "\n",
    "State['GEOID'] = State['GEOID'].astype(str)\n",
    "tract_low_income = State.groupby('GEOID').first().reset_index()\n",
    "tract_low_income['GEOID'] = tract_low_income['GEOID'].astype(str)\n",
    "tract_low_income['low_income_status'] = tract_low_income.apply(lambda row: is_low_income(row, Metro), axis=1)\n",
    "\n",
    "State = State.merge(tract_low_income[['GEOID', 'low_income_status']], on='GEOID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44019abe-53db-40fb-ba9e-48b9e6e38307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Estimate households per grid\n",
    "tract_area_totals = State.groupby('GEOID')['area'].sum().reset_index()\n",
    "tract_area_totals.rename(columns={'area': 'total_area'}, inplace=True)\n",
    "State = State.merge(tract_area_totals, on='GEOID', how='left')\n",
    "State['area_proportion'] = State['area'] / State['total_area']\n",
    "State['grid_households'] = State['tothouseho'] * State['area_proportion']\n",
    "State['grid_novehicles'] = State.apply(\n",
    "    lambda row: (row['novehicles'] / row['tothouseho'] * row['grid_households']) if row['tothouseho'] > 0 and row['novehicles'] > 0 else 0,\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4d968e-ce7e-475c-a37e-404d24661e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Create a dictionary of unique GEOIDs\n",
    "tract_dict = {}\n",
    "for geoid in State['GEOID'].unique():\n",
    "    tract_dict[geoid] = State[State['GEOID'] == geoid][[\n",
    "        'low_income_status', 'grid_popul', 'distance', 'totalpop', 'geometry',\n",
    "        'grid_households', 'grid_novehicles'\n",
    "    ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b2aeca-f99a-40e9-89ee-8e8c4d63a505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Define urban/rural classification and distance thresholds\n",
    "def is_rural(row):\n",
    "    return row['totalpop'] < 2500\n",
    "\n",
    "urban_distance_threshold = 1.0 # miles\n",
    "rural_distance_threshold = 10.0  # miles\n",
    "no_vehicle_distance_threshold = 0.5  # miles\n",
    "far_distance_threshold = 20.0  # miles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec8e7b3-71bb-4180-841f-6d9695e32664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Process tracts to evaluate low-income and low-access\n",
    "all_tracts = []\n",
    "for geoid, tract_data in tract_dict.items():\n",
    "    tract_totalpop = tract_data['totalpop'].iloc[0]\n",
    "    low_income_status = tract_data['low_income_status'].iloc[0]\n",
    "    tract_geometry = tract_data['geometry'].unary_union\n",
    "    \n",
    "    # Low-income check\n",
    "    is_low_income = low_income_status == \"Yes\"\n",
    "    \n",
    "    # Low-access check for low-income tracts\n",
    "    is_low_access_low_income = False\n",
    "    if is_low_income:\n",
    "        is_tract_rural = is_rural(tract_data.iloc[0])\n",
    "        distance_threshold = rural_distance_threshold if is_tract_rural else urban_distance_threshold\n",
    "        far_grids = tract_data[tract_data['distance'] > distance_threshold]\n",
    "        far_population = far_grids['grid_popul'].sum()\n",
    "        if tract_totalpop > 0:\n",
    "            far_percentage = (far_population / tract_totalpop) * 100\n",
    "        else:\n",
    "            far_percentage = 0\n",
    "        if far_population >= 500 or far_percentage >= 33:\n",
    "            is_low_access_low_income = True\n",
    "    \n",
    "    # Low-access check for non-low-income tracts (USDA criteria)\n",
    "    is_low_access_non_low_income = False\n",
    "    if not is_low_income:\n",
    "        # Option 1: Households > 0.5 miles with no vehicle access\n",
    "        far_no_vehicle_grids = tract_data[\n",
    "            (tract_data['distance'] > no_vehicle_distance_threshold) &\n",
    "            (tract_data['grid_novehicles'] > 0)\n",
    "        ]\n",
    "        far_no_vehicle_households = far_no_vehicle_grids['grid_novehicles'].sum()\n",
    "        # Option 2: Population > 20 miles (no vehicle check)\n",
    "        far_grids = tract_data[tract_data['distance'] > far_distance_threshold]\n",
    "        far_population = far_grids['grid_popul'].sum()\n",
    "        if tract_totalpop > 0:\n",
    "            far_percentage = (far_population / tract_totalpop) * 100\n",
    "        else:\n",
    "            far_percentage = 0\n",
    "        if far_no_vehicle_households >= 100 or far_population >= 500 or far_percentage >= 33:\n",
    "            is_low_access_non_low_income = True\n",
    "    \n",
    "    # Low-access overall (either income-based or USDA criteria)\n",
    "    is_low_access = is_low_access_low_income or is_low_access_non_low_income\n",
    "    \n",
    "    all_tracts.append({\n",
    "        'GEOID': geoid,\n",
    "        'low_income_status': low_income_status,\n",
    "        'is_low_access': is_low_access,\n",
    "        'is_low_access_low_income': is_low_access_low_income,\n",
    "        'is_low_access_non_low_income': is_low_access_non_low_income,\n",
    "        'geometry': tract_geometry\n",
    "    })\n",
    "\n",
    "all_tracts_gdf = gpd.GeoDataFrame(all_tracts, geometry='geometry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ff41e4-39ce-4655-991a-0450dac252a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Reproject to Mercator (EPSG:3857)\n",
    "all_tracts_gdf = all_tracts_gdf.set_crs(epsg=5070, allow_override=True)\n",
    "all_tracts_gdf = all_tracts_gdf.to_crs(epsg=3857)\n",
    "\n",
    "State_boundary = State.dissolve().boundary\n",
    "State_boundary = State_boundary.set_crs(epsg=5070, allow_override=True)\n",
    "State_boundary = State_boundary.to_crs(epsg=3857)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a117257-723d-477e-80fd-cf5e7f8d65cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Create three subplots\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(24, 8), sharey=True)\n",
    "\n",
    "# Plot 1: Low Income Only\n",
    "State_boundary.plot(ax=ax1, color='none', edgecolor='gray', linewidth=1.0, alpha=0.7, zorder=1)\n",
    "colors1 = ['green' if row['low_income_status'] == \"Yes\" else 'white' for _, row in all_tracts_gdf.iterrows()]\n",
    "all_tracts_gdf.plot(color=colors1, edgecolor='black', linewidth=0.5, ax=ax1, alpha=0.5, zorder=2)\n",
    "ax1.set_title('Low Income Only in State', fontsize=10)\n",
    "legend_elements1 = [\n",
    "    Patch(facecolor='green', edgecolor='black', label='Low-Income'),\n",
    "    Patch(facecolor='white', edgecolor='black', label='Other Tracts', alpha=0.5)\n",
    "]\n",
    "ax1.legend(handles=legend_elements1, loc='upper right', title='Tract Status')\n",
    "ax1.set_axis_off()\n",
    "\n",
    "# Plot 2: Low Access Only\n",
    "State_boundary.plot(ax=ax2, color='none', edgecolor='gray', linewidth=1.0, alpha=0.7, zorder=1)\n",
    "colors2 = ['blue' if row['is_low_access'] else 'white' for _, row in all_tracts_gdf.iterrows()]\n",
    "all_tracts_gdf.plot(color=colors2, edgecolor='black', linewidth=0.5, ax=ax2, alpha=0.5, zorder=2)\n",
    "ax2.set_title('Low Access Only in State', fontsize=10)\n",
    "legend_elements2 = [\n",
    "    Patch(facecolor='blue', edgecolor='black', label='Low-Access'),\n",
    "    Patch(facecolor='white', edgecolor='black', label='Other Tracts', alpha=0.5)\n",
    "]\n",
    "ax2.legend(handles=legend_elements2, loc='upper right', title='Tract Status')\n",
    "ax2.set_axis_off()\n",
    "\n",
    "# Plot 3: Low Income and Low Access\n",
    "State_boundary.plot(ax=ax3, color='none', edgecolor='gray', linewidth=1.0, alpha=0.7, zorder=1)\n",
    "colors3 = ['red' if row['low_income_status'] == \"Yes\" and row['is_low_access'] else 'white' for _, row in all_tracts_gdf.iterrows()]\n",
    "all_tracts_gdf.plot(color=colors3, edgecolor='black', linewidth=0.5, ax=ax3, alpha=0.5, zorder=2)\n",
    "ax3.set_title('Low Income and Low Access in State', fontsize=10)\n",
    "legend_elements3 = [\n",
    "    Patch(facecolor='red', edgecolor='black', label='Low-Income & Low-Access'),\n",
    "    Patch(facecolor='white', edgecolor='black', label='Other Tracts', alpha=0.5)\n",
    "]\n",
    "ax3.legend(handles=legend_elements3, loc='upper right', title='Tract Status')\n",
    "ax3.set_axis_off()\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
